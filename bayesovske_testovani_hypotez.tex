\chapter{Bayesovské testování hypotéz}
Testujeme hypotézy $\hypothesis{\t\in\Theta_0}{\t\in\Theta_1} \,(\Theta
=\Theta_0 \biguplus \Theta_1)$. Znáhodníme $\t\sim\pi(\t)$ apriorní informaci (vlastní/nevlastní/konstanta).
\begin{description}
	\item[Apriorní test $H_0$:] $\PP^\pi(H_0)=\PP^\pi(\t\in\Theta_0)\stackrel{?}{>}\frac{1}{2}$ $\Rightarrow$ $H_0$ přijmeme.
	\item[Aposteriorní test $H_0$:] Máme $\pi(\t)$, z toho data $\textbf{X}\sim\fex$, z toho aktualizujeme $\pi(\t|\textbf{x})$. Nakonec tedy 
	\[
	\begin{split}
	 \PP^\pi(H_0|\textbf{x})=\PP^\pi(\t\in\Theta_0|\textbf{x})&\stackrel{?}{>}\frac{1}{2}\quad\Rightarrow\quad H_0\text{ přijmeme.}\\
	 \int_{\Theta_0}\pi(\t|\textbf{x})\d\t & \lessgtr \frac{1}{2},
	\end{split}
	\]
	kde $\pi(\t|\textbf{x})= \frac{f\pi(\t)}{\int_\Theta f\pi(\t)\d\t}$.
\end{description}

Natavujeme tedy rozhodovací prostor $\mathscr{D}=\{0,~1\}=\{\text{no }H_0,~\text{yes }H_0\}$ a nastavujeme parametrickou funkci
$$ \tau(\t)=I_{\Theta_0}=\begin{cases}
1& \t\in\Theta_0~(H_0\text{ platí}),\\0& \t\in\Theta_1~(H_1\text{ platí}),
\end{cases}$$ s čímž přišel Neyman s Pearsonem (a Fisherem) už kolem roku 1950 ($W\subset\R^n$, $\PP(\textbf{X}\in W|H_0)\leq \alpha$ a $\beta$ je síla testu).
\begin{theorem}
	Volme ztrátovou funkci ($a_0,a_1>0$) $$L_{a_0-a_1}(\t,\delta)=\begin{cases}
	0&\delta=I_{\Theta_0}(\t)=\tau(\t)~(\text{trefa}),\\a_0& \t\in\Theta_0(H_0)\wedge \delta=0~(\text{chyba I. druhu}),\\a_1& \t\in\Theta_1(H_1)\wedge \delta=1~(\text{chyba II. druhu}),
	\end{cases}$$
	Pak $$\delta^\pi=\begin{cases}
	1& \text{pokud }\PP^\pi(\t\in\Theta_0|\textbf{x})>\frac{a_1}{a_0+a_1},\\
	0& \text{pokud }\PP^\pi(\t\in\Theta_0|\textbf{x})\leq\frac{a_1}{a_0+a_1},
	\end{cases}$$ kde $\frac{a_1}{a_0+a_1}=\frac{1}{1+\frac{a_0}{a_1}}$ je závislá na poměru $\frac{a_0}{a_1}$. Pro $a_0=a_1=1$ je pak hranice $\frac{1}{2}$.
	\begin{proof}
		Vezmeme aposteriorní bayesovské riziko (za $L$ bereme $L_{a_0-a_1}(\t,\delta)$ )
		\[
		\begin{split}
		\rho(\pi,\delta|\textbf{x})&=\E^\pi\big[L\big(\t,\delta(\textbf{x})\big)\big| \textbf{x}\big]=0\cdot\PP^{\pi}(...)+a_0\cdot \PP^\pi(\t\in\Theta_0|\textbf{x})\cdot I_{\{0\}}(\delta)+a_1 \cdot\PP^\pi (\t\in\Theta_1|\textbf{x})\cdot I_{\{1\}}(\delta)=\\&=\begin{cases}
		a_0\cdot \PP^\pi(\t\in\Theta_0|\textbf{x})&\text{pokud }\delta(\textbf{x})=0,\\
		a_1\cdot \PP^\pi(\t\in\Theta_1|\textbf{x})&\text{pokud }\delta(\textbf{x})=1,
		\end{cases}
		\end{split}
		\] 		
		$$ \delta^\pi(\textbf{x})=\argmin_\delta \rho=\begin{cases}
		1&\text{pokud }a_1\cdot\PP^\pi(\t\in\Theta_1|\textbf{x})<a_0\cdot\PP^\pi(\t\in\Theta_0|\textbf{x}),\\
		0&\text{pokud }a_1\cdot\PP^\pi(\t\in\Theta_1|\textbf{x})\geq a_0\cdot\PP^\pi(\t\in\Theta_0|\textbf{x}),\\
		\end{cases} $$
		a z $a_1\cdot\big(1-\PP^\pi(\t\in\Theta_0|\textbf{x})\big)<a_0\cdot\PP^\pi(\t\in\Theta_0|\textbf{x})$ spočítáme $\PP^\pi(\t\in\Theta_0|\textbf{x})>\frac{a_1}{a_0+a_1}\Big(=\frac{1}{2}\Big)$.
	\end{proof}
\end{theorem}
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.7\linewidth]{pictures/last0}
			\caption{popis}
			\label{fig:last0}
		\end{figure}
\begin{remark}
	Bayes umožňuje symetrizovat rozhodovací úlohu ($a_0=a_1$) nebo penalizovat v závislosti na úloze, experimentu nebo "datech".
	
Bayesovské testování hypotéz se vyhýbá nutnosti nastavení $\alpha\in(0,1)$ ($\alpha$ ovlivňuje $\beta$ sílu testu).
\end{remark}
\begin{define}
	Definujeme \textbf{Bayesovský faktor} jako$$ B^\pi(\textbf{x})=\frac{\frac{\PP^\pi(\t\in\Theta_0|\textbf{x})}{\PP^\pi(\t\in\Theta_1|\textbf{x})}}{\frac{\PP^\pi(\t\in\Theta_0)}{\PP^\pi(\t\in\Theta_1)}}.$$
	Říká, jaký je vliv dat na testování hypotéz oproti tomu, když ta data vůbec nepoužiji. Pokud $B^\pi(\textbf{x})>1$, tak data se spíše přiklánějí k $H_0$.
\end{define}
\begin{remark}
	Mějme například $\Theta_0=\{\t_0\}$, $\Theta_1=\{\t_1\}$, \[
	\begin{split}
	\PP^\pi(\t\in\Theta_0)=\PP(\t=\t_0)\equal{ozn}\pi_0,&\quad \PP^\pi(\t\in\Theta_1)=\PP(\t=\t_1)\equal{ozn}\pi_1\\ \PP^\pi(\t=\t_0|\textbf{x})=\pi(\t_0|\textbf{x})=\frac{f_0\pi_0}{f_0\pi_0+f_1\pi_1}, &\quad \PP^\pi(\t=\t_1|\textbf{x})=\pi(\t_1|\textbf{x})=\frac{f_1\pi_1}{f_0\pi_0+f_1\pi_1}.
	\end{split}
	\]Z toho pak 
	$ B^\pi(\textbf{x})=\frac{\frac{f_0\pi_0}{f_1\pi_1}}{\frac{\pi_0}{\pi_1}}=\frac{f_0}{f_1}=\frac{L_0}{L_1}$ (věrohodnostní poměr - \textit{Likelihood ratio}).
\end{remark}

Pro obecnou úlohu označme $\rho_0=\PP^\pi(\t\in\Theta_0)$, $\rho_1=\PP^\pi(\t\in\Theta_1)=1-\rho_0$. Přijímáme $H_0$, pokud $$a_1\cdot \PP^\pi(\t\in\Theta_1|\textbf{x})<a_0\cdot\PP^\pi(\t\in\Theta_0|\textbf{x}),~(\delta(\textbf{x})=1).$$ 
Potom po úpravě a vydělení $\frac{\rho_0}{\rho_1}$ dostáváme
$$\frac{a_1/a_0}{\rho_0/\rho_1}<\underbrace{\frac{\frac{\PP^\pi(\t\in\Theta_0|\textbf{x})}{\PP^\pi(\t\in\Theta_1|\textbf{x})}}{\frac{\rho_0}{\rho_1}}}_{B^\pi(\textbf{x})}.$$
(Dualita mezi $\frac{a_1}{a_0}$ a $\frac{\rho_0}{\rho_1}$.)
\begin{remark}[Sekvenční Bayesovské testování hypotéz]
	Máme apriorní pravděpodobnosti $\rho_0,\rho_1$, naměříme data $\textbf{x}$. Z toho pak vyrobíme aposteriorní hustotu $\pi(\t|\textbf{x})$, a pak se rozhodujeme mezi $H_0$ a $H_1$. Nyní můžeme sekvenčně pokračovat dál tak, že vezmeme $\tilde{\pi}(\t)=\pi(\t|\textbf{x})$ a naměříme další data $\tilde{\textbf{x}}\sim \tilde{f}$. Potom získáme aposteriorní hustotu $\tilde{\pi}(\t|\tilde{\textbf{x}},\textbf{x})$ a rozhodneme se mezi $H_0$ a $H_1$. A znovu můžeme sekvenčně pokračovat tak, že $\tilde{\tilde{\pi}}(\t)=\tilde{\pi}(\t|\tilde{\textbf{x}},\textbf{x})$ a pokračujeme dále analogicky.
\end{remark}


\underline{Aspekt Bayesovského testování hypotéz:}

Testujeme $\hypothesis{\t=\t_0}{\t\neq\t_0}$. Nastavíme $\t\sim\pi(\t)$ a předpokládáme, že je spojitá. Pak 
$$ \rho_0=\PP^\pi(\t=\t_0)\overset{\text{\footnotemark}}{=}0\quad\Rightarrow\quad \PP^\pi(\t=\t_0|\textbf{x})=\frac{f_0\pi_0}{c}=0,$$
\footnotetext{Ve spojitém modelu je pravděpodobnost, že náhodná veličina $\t$ nabude jedné izolované hodnoty, nulová.}
případně analogicky pro $1$. Z toho zároveň vyplývá, že $\rho_0=\begin{cases}
0\\1
\end{cases}$ je absorbující stav. Dále víme, že $\pi(\t)$ je konstantní, tudíž nepreferujeme žádnou konkrétní hodnotu $\t\in\Theta$. 

\begin{example}
	Mějme $H_0$ hypotézu, že zítra bude pršet s pravděpodobností rovnu $0.7$ a $H_1$ jako $\neq 0.7$. 
	
	Jak na to? Buď $$\hypothesis{\t\in(\t_0-\epsilon,\t_0+\epsilon)}{\t\notin(\t_0-\epsilon,\t_0+\epsilon)}$$
	nebo volit $\pi(\t)=\rho_0\cdot \delta_{\t_0}+(1-\rho_0)\cdot\pi_1(\t)$, kde $\rho_0$ volíme větší než $0$, případně menší než $1$ (pak $\rho_1=1-\rho_0$).
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.5\linewidth]{pictures/last1}
		\caption{Tímto způsobem vnášíme do BTH dodatečnou apriorní informaci.}
		\label{fig:last1}
	\end{figure}
	Při takto upravené apriorní hustotě můžeme spočítat aposteriorní hustotu
	\begin{align*}
\pi(\t_0|\textbf{x})&=\PP^\pi(\t=\t_0|\textbf{x})=\frac{f_0\cdot\pi(\t_0)}{\int_\Theta f_X \cdot \pi\,\d\t}=\frac{f_0\cdot\rho_0}{f_0\cdot\rho_0+(1-\rho_0)\underbrace{\int_{\Theta_1}f\cdot\pi(\t)\,\d\t}_{m_1(\textbf{x})}}= \\ 
&=\Big[1+\frac{1-\rho_0}{\rho_0}\frac{m_1(\textbf{x})}{f_0(\textbf{x})}\Big]^{-1}<\frac{a_1}{a_0+a_1},
\end{align*}
tedy $B^\pi(\textbf{x})=\frac{f_0(\textbf{x})}{m_1(\textbf{x})}$.
\end{example}
\begin{example}
	Mějme $X\sim\NN(\mu,1)$ a chceme testovat $\hypothesis{\mu=0}{\mu\neq0}$, kde $\mu\in\R$. Víme, že $\rho_0=\frac{1}{2}$, $\rho_1=\frac{1}{2}$ (tzn. $H_0$ věříme na 50\%). Potom volíme
	\begin{enumerate}[a)]
		\item $$ \pi(\mu)=\frac{1}{2}\delta_0+\frac{1}{2}\pi_1(\t)\text{ , kde }\pi_1(\mu)=1\text{ na }\mu\neq0\quad(\text{nevlastní apriorní hustota}).$$
		Potom $$ \pi(\mu=0|\underbrace{\textbf{x}}_{=x})=\frac{1}{1+\sqrt{2\pi} \e{x^2/2}}\stackrel{\forall x\in\R}{\leq}\frac{1}{1+\sqrt{2\pi}}=0.285\quad \text{tzn. vždy zamítáme }H_0!$$
		\item Nyní budeme předpokládat, že $\pi_1(\mu)=\NN(m=0,\tau^2)$ (vlastní), $\rho=\frac{1}{2}$. Potom $$\pi(\mu=0|\textbf{x})=[]^{-1}\stackrel{\tau\to+\infty}{\longrightarrow}1.$$
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.5\linewidth]{pictures/last01}
			\caption{b)}
			\label{fig:last01}
		\end{figure}
		
	\end{enumerate}
$$ \begin{array}{c|c|c|c|c|c}
x & 0 & 0.68 & 1.28 & 1.96 & ... \\\hline
\substack{\pi(0|x)\\ \tau=1}& 0.586 & 0.557 & 0.484 & 0.351 & ... \\\hline
\substack{\pi(0|x)\\ \tau=10}& 0.768 & 0.729 & 0.612 & 0.366 & ...
\end{array}
 $$
\end{example}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{pictures/last02}
	\caption{Jeffreys-Lindley Paradox}
	\label{fig:last02}
\end{figure}
